package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"os"
	"os/signal"
	"strconv"
	"strings"
	"syscall"
	"time"

	"github.com/confluentinc/confluent-kafka-go/v2/kafka"
	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
	"github.com/go-chi/cors"
	"github.com/google/uuid"
	"github.com/neo4j/neo4j-go-driver/v5/neo4j"
	"github.com/redis/go-redis/v9"
	
	"cube-castle-deployment-test/internal/cache"
)

// æ–°ä¸€ä»£ç¼“å­˜ç®¡ç†æœåŠ¡
type NextGenCacheService struct {
	cacheManager  *cache.UnifiedCacheManager
	cdcConsumer   *kafka.Consumer
	eventBus      *cache.CacheEventBus
	logger        *log.Logger
	config        *ServiceConfig
	ctx           context.Context
	cancel        context.CancelFunc
}

// æœåŠ¡é…ç½®
type ServiceConfig struct {
	RedisAddr      string
	RedisPassword  string
	KafkaBrokers   []string
	Neo4jURI       string
	Neo4jUsername  string
	Neo4jPassword  string
	Port           string
	WriteThrough   bool
	ConsistencyMode string
}

// åˆå§‹åŒ–æœåŠ¡
func NewNextGenCacheService(config *ServiceConfig, logger *log.Logger) (*NextGenCacheService, error) {
	ctx, cancel := context.WithCancel(context.Background())

	// 1. åˆ›å»ºRediså®¢æˆ·ç«¯
	redisClient := redis.NewClient(&redis.Options{
		Addr:     config.RedisAddr,
		Password: config.RedisPassword,
		DB:       0,
	})

	// æµ‹è¯•Redisè¿æ¥
	if _, err := redisClient.Ping(ctx).Result(); err != nil {
		cancel()
		return nil, fmt.Errorf("Redisè¿æ¥å¤±è´¥: %w", err)
	}

	// 2. åˆ›å»ºNeo4jé©±åŠ¨
	driver, err := neo4j.NewDriverWithContext(config.Neo4jURI, neo4j.BasicAuth(config.Neo4jUsername, config.Neo4jPassword, ""))
	if err != nil {
		cancel()
		return nil, fmt.Errorf("åˆ›å»ºNeo4jé©±åŠ¨å¤±è´¥: %w", err)
	}

	if err = driver.VerifyConnectivity(ctx); err != nil {
		cancel()
		return nil, fmt.Errorf("Neo4jè¿æ¥éªŒè¯å¤±è´¥: %w", err)
	}

	// 3. åˆ›å»ºL3æŸ¥è¯¢æœåŠ¡
	l3Query := NewNeo4jQueryService(driver, logger)

	// 4. åˆ›å»ºç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
	cacheConfig := &cache.CacheConfig{
		L1TTL:           5 * time.Minute,
		L2TTL:           30 * time.Minute,
		L1MaxSize:       2000,
		WriteThrough:    config.WriteThrough,
		ConsistencyMode: config.ConsistencyMode,
		Namespace:       "org_v2",
	}

	cacheManager := cache.NewUnifiedCacheManager(redisClient, l3Query, cacheConfig, logger)

	// 5. åˆ›å»ºKafkaæ¶ˆè´¹è€…
	kafkaConfig := &kafka.ConfigMap{
		"bootstrap.servers": strings.Join(config.KafkaBrokers, ","),
		"group.id":          "nextgen-cache-service",
		"auto.offset.reset": "latest",
		"enable.auto.commit": true,
	}

	consumer, err := kafka.NewConsumer(kafkaConfig)
	if err != nil {
		cancel()
		return nil, fmt.Errorf("åˆ›å»ºKafkaæ¶ˆè´¹è€…å¤±è´¥: %w", err)
	}

	// 6. åˆ›å»ºäº‹ä»¶æ€»çº¿
	eventBus := cache.NewCacheEventBus()

	service := &NextGenCacheService{
		cacheManager: cacheManager,
		cdcConsumer:  consumer,
		eventBus:     eventBus,
		logger:       logger,
		config:       config,
		ctx:          ctx,
		cancel:       cancel,
	}

	return service, nil
}

// å¯åŠ¨æœåŠ¡
func (service *NextGenCacheService) Start() error {
	service.logger.Println("ğŸš€ å¯åŠ¨æ–°ä¸€ä»£ç¼“å­˜ç®¡ç†æœåŠ¡...")

	// 1. å¯åŠ¨CDCæ¶ˆè´¹è€…
	go service.startCDCConsumer()

	// 2. å¯åŠ¨HTTPæœåŠ¡å™¨
	go service.startHTTPServer()

	// 3. å¯åŠ¨å¥åº·æ£€æŸ¥
	go service.startHealthMonitor()

	// 4. ç­‰å¾…åœæ­¢ä¿¡å·
	return service.waitForShutdown()
}

// å¯åŠ¨CDCæ¶ˆè´¹è€…
func (service *NextGenCacheService) startCDCConsumer() {
	topics := []string{"organization_db.public.organization_units"}
	
	if err := service.cdcConsumer.SubscribeTopics(topics, nil); err != nil {
		service.logger.Printf("âŒ è®¢é˜…Kafkaä¸»é¢˜å¤±è´¥: %v", err)
		return
	}

	service.logger.Printf("ğŸ“¡ CDCæ¶ˆè´¹è€…å¯åŠ¨ï¼Œç›‘å¬ä¸»é¢˜: %v", topics)

	for {
		select {
		case <-service.ctx.Done():
			service.logger.Println("CDCæ¶ˆè´¹è€…æ”¶åˆ°åœæ­¢ä¿¡å·")
			return
		default:
			msg, err := service.cdcConsumer.ReadMessage(1000)
			if err != nil {
				if err.(kafka.Error).Code() == kafka.ErrTimedOut {
					continue
				}
				service.logger.Printf("âš ï¸ æ¶ˆè´¹æ¶ˆæ¯å¤±è´¥: %v", err)
				continue
			}

			if err := service.processCDCMessage(msg); err != nil {
				service.logger.Printf("âŒ å¤„ç†CDCæ¶ˆæ¯å¤±è´¥: %v", err)
			}
		}
	}
}

// å¤„ç†CDCæ¶ˆæ¯
func (service *NextGenCacheService) processCDCMessage(msg *kafka.Message) error {
	topic := *msg.TopicPartition.Topic
	
	if topic != "organization_db.public.organization_units" {
		return nil
	}

	// è§£æDebeziumæ¶ˆæ¯
	var debeziumMsg struct {
		Payload struct {
			Before *map[string]interface{} `json:"before"`
			After  *map[string]interface{} `json:"after"`
			Op     string                  `json:"op"`
			TsMs   int64                   `json:"ts_ms"`
		} `json:"payload"`
	}

	if err := json.Unmarshal(msg.Value, &debeziumMsg); err != nil {
		return fmt.Errorf("è§£æDebeziumæ¶ˆæ¯å¤±è´¥: %w", err)
	}

	// è½¬æ¢ä¸ºç»Ÿä¸€äº‹ä»¶æ ¼å¼
	event := cache.CDCEvent{
		EventID:   uuid.New().String(),
		Timestamp: debeziumMsg.Payload.TsMs,
		Source:    "debezium",
	}

	switch debeziumMsg.Payload.Op {
	case "c":
		event.Operation = "CREATE"
		event.After = *debeziumMsg.Payload.After
	case "u":
		event.Operation = "UPDATE"
		event.After = *debeziumMsg.Payload.After
		if debeziumMsg.Payload.Before != nil {
			event.Before = *debeziumMsg.Payload.Before
		}
	case "d":
		event.Operation = "DELETE"
		if debeziumMsg.Payload.Before != nil {
			event.Before = *debeziumMsg.Payload.Before
		}
	}

	// æå–ç§Ÿæˆ·IDå’Œå®ä½“ID
	var data map[string]interface{}
	if event.After != nil {
		data = event.After
	} else if event.Before != nil {
		data = event.Before
	}

	if data != nil {
		if tenantID, ok := data["tenant_id"].(string); ok {
			event.TenantID = tenantID
		}
		if code, ok := data["code"].(string); ok {
			event.EntityID = code
		}
	}

	event.EntityType = "organization"

	service.logger.Printf("ğŸ“¨ æ”¶åˆ°CDCäº‹ä»¶: %s %s:%s", event.Operation, event.EntityType, event.EntityID)

	// å¤„ç†äº‹ä»¶
	return service.cacheManager.HandleCDCEvent(service.ctx, event)
}

// å¯åŠ¨HTTPæœåŠ¡å™¨
func (service *NextGenCacheService) startHTTPServer() {
	r := chi.NewRouter()

	// ä¸­é—´ä»¶
	r.Use(middleware.Logger)
	r.Use(middleware.Recoverer)
	r.Use(middleware.Timeout(30 * time.Second))

	// CORS
	r.Use(cors.Handler(cors.Options{
		AllowedOrigins:   []string{"*"},
		AllowedMethods:   []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"},
		AllowedHeaders:   []string{"*"},
		AllowCredentials: true,
		MaxAge:           300,
	}))

	// APIè·¯ç”±
	r.Route("/api/v2", func(r chi.Router) {
		r.Get("/organizations", service.handleGetOrganizations)
		r.Get("/organizations/{code}", service.handleGetOrganization)
		r.Get("/organizations/stats", service.handleGetStats)
		
		// ç¼“å­˜ç®¡ç†æ¥å£
		r.Delete("/cache/refresh", service.handleRefreshCache)
		r.Get("/cache/stats", service.handleGetCacheStats)
		r.Get("/cache/consistency", service.handleCheckConsistency)
	})

	// å¥åº·æ£€æŸ¥
	r.Get("/health", service.handleHealth)
	r.Get("/metrics", service.handleMetrics)

	server := &http.Server{
		Addr:    ":" + service.config.Port,
		Handler: r,
	}

	service.logger.Printf("ğŸŒ HTTPæœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ %s", service.config.Port)
	if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
		service.logger.Printf("âŒ HTTPæœåŠ¡å™¨é”™è¯¯: %v", err)
	}
}

// å¤„ç†è·å–ç»„ç»‡åˆ—è¡¨
func (service *NextGenCacheService) handleGetOrganizations(w http.ResponseWriter, r *http.Request) {
	// è§£ææŸ¥è¯¢å‚æ•°
	tenantID := uuid.MustParse("3b99930c-4dc6-4cc9-8e4d-7d960a931cb9") // é»˜è®¤ç§Ÿæˆ·
	
	first := 50
	if f := r.URL.Query().Get("first"); f != "" {
		if parsed, err := strconv.Atoi(f); err == nil {
			first = parsed
		}
	}
	
	offset := 0
	if o := r.URL.Query().Get("offset"); o != "" {
		if parsed, err := strconv.Atoi(o); err == nil {
			offset = parsed
		}
	}
	
	searchText := r.URL.Query().Get("searchText")
	
	params := cache.QueryParams{
		First:      first,
		Offset:     offset,
		SearchText: searchText,
	}

	// é€šè¿‡ç¼“å­˜ç®¡ç†å™¨è·å–æ•°æ®
	startTime := time.Now()
	orgs, err := service.cacheManager.GetOrganizations(r.Context(), tenantID, params)
	duration := time.Since(startTime)

	if err != nil {
		service.logger.Printf("âŒ è·å–ç»„ç»‡åˆ—è¡¨å¤±è´¥: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	// è¿”å›ç»“æœ
	result := map[string]interface{}{
		"data":          orgs,
		"total":         len(orgs),
		"query_time_ms": duration.Milliseconds(),
		"cached":        duration < 10*time.Millisecond, // ç®€å•çš„ç¼“å­˜å‘½ä¸­åˆ¤æ–­
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(result)

	service.logger.Printf("âœ… ç»„ç»‡åˆ—è¡¨æŸ¥è¯¢å®Œæˆ: %dæ¡è®°å½•, è€—æ—¶: %v", len(orgs), duration)
}

// å¤„ç†è·å–å•ä¸ªç»„ç»‡
func (service *NextGenCacheService) handleGetOrganization(w http.ResponseWriter, r *http.Request) {
	code := chi.URLParam(r, "code")
	tenantID := uuid.MustParse("3b99930c-4dc6-4cc9-8e4d-7d960a931cb9")

	startTime := time.Now()
	org, err := service.cacheManager.GetOrganization(r.Context(), tenantID, code)
	duration := time.Since(startTime)

	if err != nil {
		service.logger.Printf("âŒ è·å–ç»„ç»‡å¤±è´¥: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	if org == nil {
		http.Error(w, "ç»„ç»‡ä¸å­˜åœ¨", http.StatusNotFound)
		return
	}

	result := map[string]interface{}{
		"data":          org,
		"query_time_ms": duration.Milliseconds(),
		"cached":        duration < 10*time.Millisecond,
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(result)

	service.logger.Printf("âœ… ç»„ç»‡æŸ¥è¯¢å®Œæˆ: %s, è€—æ—¶: %v", code, duration)
}

// å¤„ç†è·å–ç»Ÿè®¡ä¿¡æ¯
func (service *NextGenCacheService) handleGetStats(w http.ResponseWriter, r *http.Request) {
	tenantID := uuid.MustParse("3b99930c-4dc6-4cc9-8e4d-7d960a931cb9")

	startTime := time.Now()
	stats, err := service.cacheManager.GetOrganizationStats(r.Context(), tenantID)
	duration := time.Since(startTime)

	if err != nil {
		service.logger.Printf("âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	result := map[string]interface{}{
		"data":          stats,
		"query_time_ms": duration.Milliseconds(),
		"cached":        duration < 10*time.Millisecond,
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(result)

	service.logger.Printf("âœ… ç»Ÿè®¡æŸ¥è¯¢å®Œæˆ, è€—æ—¶: %v", duration)
}

// å¤„ç†ç¼“å­˜åˆ·æ–°
func (service *NextGenCacheService) handleRefreshCache(w http.ResponseWriter, r *http.Request) {
	tenantID := uuid.MustParse("3b99930c-4dc6-4cc9-8e4d-7d960a931cb9")
	entityType := r.URL.Query().Get("type")
	entityID := r.URL.Query().Get("id")

	if entityType == "" {
		entityType = "organizations"
	}

	err := service.cacheManager.RefreshCache(r.Context(), tenantID, entityType, entityID)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	result := map[string]string{
		"message": fmt.Sprintf("ç¼“å­˜å·²åˆ·æ–°: %s:%s", entityType, entityID),
		"status":  "success",
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(result)
}

// å¤„ç†è·å–ç¼“å­˜ç»Ÿè®¡
func (service *NextGenCacheService) handleGetCacheStats(w http.ResponseWriter, r *http.Request) {
	stats := service.cacheManager.GetCacheStats(r.Context())

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(stats)
}

// å¤„ç†ä¸€è‡´æ€§æ£€æŸ¥
func (service *NextGenCacheService) handleCheckConsistency(w http.ResponseWriter, r *http.Request) {
	// ç®€åŒ–ç‰ˆä¸€è‡´æ€§æ£€æŸ¥
	result := map[string]interface{}{
		"status":     "healthy",
		"checked_at": time.Now(),
		"message":    "ç¼“å­˜ä¸€è‡´æ€§æ£€æŸ¥åŠŸèƒ½å¾…å®ç°",
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(result)
}

// å¥åº·æ£€æŸ¥
func (service *NextGenCacheService) handleHealth(w http.ResponseWriter, r *http.Request) {
	health := map[string]interface{}{
		"service":   "nextgen-cache-service",
		"status":    "healthy",
		"timestamp": time.Now().Format(time.RFC3339),
		"features": []string{
			"ä¸‰å±‚ç¼“å­˜æ¶æ„",
			"å†™æ—¶æ›´æ–°ç­–ç•¥",
			"æ™ºèƒ½åˆ—è¡¨æ›´æ–°",
			"ä¸€è‡´æ€§ä¿éšœ",
			"CDCå®æ—¶åŒæ­¥",
		},
		"cache_stats": service.cacheManager.GetCacheStats(r.Context()),
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(health)
}

// æŒ‡æ ‡ç«¯ç‚¹
func (service *NextGenCacheService) handleMetrics(w http.ResponseWriter, r *http.Request) {
	stats := service.cacheManager.GetCacheStats(r.Context())

	metrics := fmt.Sprintf(`# NextGen Cache Service Metrics
cache_l1_hits_total %d
cache_l1_misses_total %d  
cache_l1_size_current %d
cache_l1_hit_rate %.2f
cache_l2_connected %s
cache_write_through_enabled %s
`,
		stats.L1Stats.HitCount,
		stats.L1Stats.MissCount,
		stats.L1Stats.Size,
		stats.L1Stats.HitRate,
		boolToMetric(stats.L2Connected),
		boolToMetric(stats.WriteThrough),
	)

	w.Header().Set("Content-Type", "text/plain")
	w.Write([]byte(metrics))
}

func boolToMetric(b bool) string {
	if b {
		return "1"
	}
	return "0"
}

// å¯åŠ¨å¥åº·ç›‘æ§
func (service *NextGenCacheService) startHealthMonitor() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-service.ctx.Done():
			return
		case <-ticker.C:
			stats := service.cacheManager.GetCacheStats(service.ctx)
			service.logger.Printf("ğŸ“Š ç¼“å­˜ç»Ÿè®¡: L1å‘½ä¸­ç‡=%.2f%%, L1å¤§å°=%d, L2è¿æ¥=%t, å†™æ—¶æ›´æ–°=%t",
				stats.L1Stats.HitRate*100,
				stats.L1Stats.Size,
				stats.L2Connected,
				stats.WriteThrough,
			)
		}
	}
}

// ç­‰å¾…å…³é—­ä¿¡å·
func (service *NextGenCacheService) waitForShutdown() error {
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)

	<-sigChan
	service.logger.Println("ğŸ“¡ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")

	// è®¾ç½®å…³é—­è¶…æ—¶
	shutdownTimeout := 15 * time.Second
	shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), shutdownTimeout)
	defer shutdownCancel()

	// å…³é—­æœåŠ¡
	service.cancel()

	// ç­‰å¾…æ‰€æœ‰åç¨‹ç»“æŸæˆ–è¶…æ—¶
	done := make(chan struct{})
	go func() {
		defer close(done)
		
		if service.cdcConsumer != nil {
			service.cdcConsumer.Close()
		}
		
		if service.cacheManager != nil {
			service.cacheManager.Close()
		}
		
		if service.eventBus != nil {
			service.eventBus.Close()
		}
	}()

	select {
	case <-done:
		service.logger.Println("âœ… æœåŠ¡ä¼˜é›…å…³é—­å®Œæˆ")
		return nil
	case <-shutdownCtx.Done():
		service.logger.Println("â° å…³é—­è¶…æ—¶ï¼Œå¼ºåˆ¶é€€å‡º")
		return shutdownCtx.Err()
	}
}

// ä¸»å‡½æ•°
func main() {
	logger := log.New(os.Stdout, "[NEXTGEN-CACHE] ", log.LstdFlags)

	// é…ç½®å‚æ•°
	config := &ServiceConfig{
		RedisAddr:       getEnv("REDIS_ADDR", "localhost:6379"),
		RedisPassword:   getEnv("REDIS_PASSWORD", ""),
		KafkaBrokers:    strings.Split(getEnv("KAFKA_BROKERS", "localhost:9092"), ","),
		Neo4jURI:        getEnv("NEO4J_URI", "bolt://localhost:7687"),
		Neo4jUsername:   getEnv("NEO4J_USERNAME", "neo4j"),
		Neo4jPassword:   getEnv("NEO4J_PASSWORD", "password"),
		Port:            getEnv("PORT", "8088"),
		WriteThrough:    getEnv("WRITE_THROUGH", "true") == "true",
		ConsistencyMode: getEnv("CONSISTENCY_MODE", "STRONG"),
	}

	// åˆ›å»ºæœåŠ¡
	service, err := NewNextGenCacheService(config, logger)
	if err != nil {
		log.Fatalf("âŒ åˆ›å»ºæœåŠ¡å¤±è´¥: %v", err)
	}

	// å¯åŠ¨æœåŠ¡
	logger.Println("ğŸš€ æ–°ä¸€ä»£ç¼“å­˜ç®¡ç†æœåŠ¡å¯åŠ¨...")
	if err := service.Start(); err != nil {
		log.Fatalf("âŒ æœåŠ¡è¿è¡Œå¤±è´¥: %v", err)
	}

	logger.Println("ğŸ‘‹ æ–°ä¸€ä»£ç¼“å­˜ç®¡ç†æœåŠ¡å·²é€€å‡º")
}

// è·å–ç¯å¢ƒå˜é‡
func getEnv(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}