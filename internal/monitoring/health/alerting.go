package health

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"sync"
	"time"

	pkglogger "cube-castle/pkg/logger"
)

// AlertLevel å‘Šè­¦çº§åˆ«
type AlertLevel string

const (
	AlertLevelInfo     AlertLevel = "info"
	AlertLevelWarning  AlertLevel = "warning"
	AlertLevelCritical AlertLevel = "critical"
)

// Alert å‘Šè­¦ä¿¡æ¯
type Alert struct {
	ID         string                 `json:"id"`
	Service    string                 `json:"service"`
	Component  string                 `json:"component"`
	Level      AlertLevel             `json:"level"`
	Status     HealthStatus           `json:"status"`
	Message    string                 `json:"message"`
	Details    map[string]interface{} `json:"details,omitempty"`
	Timestamp  time.Time              `json:"timestamp"`
	Resolved   bool                   `json:"resolved"`
	ResolvedAt *time.Time             `json:"resolvedAt,omitempty"`
}

// AlertRule å‘Šè­¦è§„åˆ™
type AlertRule struct {
	Name          string         `json:"name"`
	Component     string         `json:"component"`
	Condition     AlertCondition `json:"condition"`
	Level         AlertLevel     `json:"level"`
	Message       string         `json:"message"`
	Cooldown      time.Duration  `json:"cooldown"`
	MaxRetries    int            `json:"maxRetries"`
	EnabledBy     time.Time      `json:"enabledBy"`
	lastTriggered time.Time
	retryCount    int
}

// AlertCondition å‘Šè­¦æ¡ä»¶
type AlertCondition struct {
	StatusEquals     *HealthStatus  `json:"statusEquals,omitempty"`
	ResponseTimeGT   *time.Duration `json:"responseTimeGt,omitempty"`
	ConsecutiveFails *int           `json:"consecutiveFails,omitempty"`
}

// AlertChannel å‘Šè­¦æ¸ é“æ¥å£
type AlertChannel interface {
	Send(ctx context.Context, alert Alert) error
	Name() string
}

type loggerAwareChannel interface {
	SetLogger(pkglogger.Logger)
}

// WebhookChannel Webhookå‘Šè­¦æ¸ é“
type WebhookChannel struct {
	name    string
	url     string
	headers map[string]string
	timeout time.Duration
}

// NewWebhookChannel åˆ›å»ºWebhookå‘Šè­¦æ¸ é“
func NewWebhookChannel(name, url string) *WebhookChannel {
	return &WebhookChannel{
		name:    name,
		url:     url,
		headers: make(map[string]string),
		timeout: 10 * time.Second,
	}
}

func (w *WebhookChannel) Name() string {
	return w.name
}

func (w *WebhookChannel) AddHeader(key, value string) {
	w.headers[key] = value
}

func (w *WebhookChannel) Send(ctx context.Context, alert Alert) error {
	payload := map[string]interface{}{
		"alert":     alert,
		"timestamp": time.Now(),
		"source":    "cube-castle-health-monitor",
	}

	data, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("failed to marshal alert: %w", err)
	}

	ctx, cancel := context.WithTimeout(ctx, w.timeout)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "POST", w.url, bytes.NewBuffer(data))
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("User-Agent", "cube-castle-health-monitor/1.0")

	for key, value := range w.headers {
		req.Header.Set(key, value)
	}

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("failed to send webhook: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 400 {
		return fmt.Errorf("webhook returned status %d", resp.StatusCode)
	}

	return nil
}

// SlackChannel Slackå‘Šè­¦æ¸ é“
type SlackChannel struct {
	webhookURL string
	channel    string
	username   string
}

// NewSlackChannel åˆ›å»ºSlackå‘Šè­¦æ¸ é“
func NewSlackChannel(webhookURL, channel, username string) *SlackChannel {
	return &SlackChannel{
		webhookURL: webhookURL,
		channel:    channel,
		username:   username,
	}
}

func (s *SlackChannel) Name() string {
	return "slack"
}

func (s *SlackChannel) Send(ctx context.Context, alert Alert) error {
	// æ ¹æ®å‘Šè­¦çº§åˆ«é€‰æ‹©é¢œè‰²å’Œemoji
	var color, emoji string
	switch alert.Level {
	case AlertLevelCritical:
		color = "#FF0000"
		emoji = "ğŸš¨"
	case AlertLevelWarning:
		color = "#FFA500"
		emoji = "âš ï¸"
	case AlertLevelInfo:
		color = "#0000FF"
		emoji = "â„¹ï¸"
	}

	statusEmoji := ""
	switch alert.Status {
	case StatusHealthy:
		statusEmoji = "âœ…"
	case StatusDegraded:
		statusEmoji = "ğŸŸ¡"
	case StatusUnhealthy:
		statusEmoji = "âŒ"
	}

	payload := map[string]interface{}{
		"channel":  s.channel,
		"username": s.username,
		"attachments": []map[string]interface{}{
			{
				"color": color,
				"title": fmt.Sprintf("%s Cube Castle å¥åº·å‘Šè­¦", emoji),
				"text":  alert.Message,
				"fields": []map[string]interface{}{
					{
						"title": "æœåŠ¡",
						"value": alert.Service,
						"short": true,
					},
					{
						"title": "ç»„ä»¶",
						"value": alert.Component,
						"short": true,
					},
					{
						"title": "çŠ¶æ€",
						"value": fmt.Sprintf("%s %s", statusEmoji, alert.Status),
						"short": true,
					},
					{
						"title": "çº§åˆ«",
						"value": string(alert.Level),
						"short": true,
					},
					{
						"title": "æ—¶é—´",
						"value": alert.Timestamp.Format("2006-01-02 15:04:05"),
						"short": true,
					},
				},
				"footer": "Cube Castle Health Monitor",
				"ts":     alert.Timestamp.Unix(),
			},
		},
	}

	data, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("failed to marshal slack payload: %w", err)
	}

	ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "POST", s.webhookURL, bytes.NewBuffer(data))
	if err != nil {
		return fmt.Errorf("failed to create slack request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("failed to send slack webhook: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 400 {
		return fmt.Errorf("slack webhook returned status %d", resp.StatusCode)
	}

	return nil
}

// EmailChannel é‚®ä»¶å‘Šè­¦æ¸ é“ (ç®€åŒ–å®ç°)
type EmailChannel struct {
	smtpHost string
	smtpPort int
	username string
	password string
	from     string
	to       []string
	logger   pkglogger.Logger
}

func (e *EmailChannel) Name() string {
	return "email"
}

// SetLogger å…è®¸æ³¨å…¥ç»“æ„åŒ–æ—¥å¿—å™¨
func (e *EmailChannel) SetLogger(logger pkglogger.Logger) {
	if logger != nil {
		e.logger = logger.WithFields(pkglogger.Fields{
			"channel": "email",
		})
	}
}

func (e *EmailChannel) Send(ctx context.Context, alert Alert) error {
	// è¿™é‡Œåº”è¯¥å®ç°SMTPé‚®ä»¶å‘é€
	// ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œåªæ˜¯è®°å½•æ—¥å¿—
	logger := e.logger
	if logger == nil {
		logger = pkglogger.NewNoopLogger()
	}
	logger.WithFields(pkglogger.Fields{
		"channel":   "email",
		"alertId":   alert.ID,
		"level":     alert.Level,
		"service":   alert.Service,
		"component": alert.Component,
	}).Infof("EMAIL ALERT: %s", alert.Message)
	return nil
}

// AlertManager å‘Šè­¦ç®¡ç†å™¨
type AlertManager struct {
	serviceName      string
	rules            []AlertRule
	channels         []AlertChannel
	activeAlerts     map[string]*Alert
	alertHistory     []Alert
	mu               sync.RWMutex
	maxHistorySize   int
	healthStates     map[string]HealthStatus
	consecutiveFails map[string]int
	logger           pkglogger.Logger
}

// NewAlertManager åˆ›å»ºå‘Šè­¦ç®¡ç†å™¨
func NewAlertManager(serviceName string) *AlertManager {
	return &AlertManager{
		serviceName:      serviceName,
		rules:            make([]AlertRule, 0),
		channels:         make([]AlertChannel, 0),
		activeAlerts:     make(map[string]*Alert),
		alertHistory:     make([]Alert, 0),
		maxHistorySize:   1000,
		healthStates:     make(map[string]HealthStatus),
		consecutiveFails: make(map[string]int),
		logger: pkglogger.NewLogger(
			pkglogger.WithLevel(pkglogger.LevelInfo),
		).WithFields(pkglogger.Fields{
			"service":   serviceName,
			"component": "health-alerting",
		}),
	}
}

// WithLogger å…è®¸æ³¨å…¥ç»“æ„åŒ–æ—¥å¿—å™¨
func (am *AlertManager) WithLogger(logger pkglogger.Logger) *AlertManager {
	if logger != nil {
		am.logger = logger.WithFields(pkglogger.Fields{
			"service":   am.serviceName,
			"component": "health-alerting",
		})
	}
	return am
}

// AddRule æ·»åŠ å‘Šè­¦è§„åˆ™
func (am *AlertManager) AddRule(rule AlertRule) {
	am.mu.Lock()
	defer am.mu.Unlock()
	am.rules = append(am.rules, rule)
}

// AddChannel æ·»åŠ å‘Šè­¦æ¸ é“
func (am *AlertManager) AddChannel(channel AlertChannel) {
	am.mu.Lock()
	defer am.mu.Unlock()
	if lc, ok := channel.(loggerAwareChannel); ok {
		lc.SetLogger(am.logger)
	}
	am.channels = append(am.channels, channel)
}

// ProcessHealthCheck å¤„ç†å¥åº·æ£€æŸ¥ç»“æœ
func (am *AlertManager) ProcessHealthCheck(ctx context.Context, health ServiceHealth) {
	am.mu.Lock()
	defer am.mu.Unlock()

	// æ›´æ–°å¥åº·çŠ¶æ€å†å²
	for _, check := range health.Checks {
		componentKey := fmt.Sprintf("%s:%s", health.Service, check.Name)

		// è®°å½•è¿ç»­å¤±è´¥æ¬¡æ•°
		if check.Status == StatusUnhealthy {
			am.consecutiveFails[componentKey]++
		} else {
			am.consecutiveFails[componentKey] = 0
		}

		// æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘å‘Šè­¦
		am.evaluateRules(ctx, health.Service, check)

		// æ›´æ–°å¥åº·çŠ¶æ€
		am.healthStates[componentKey] = check.Status
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰å‘Šè­¦éœ€è¦è§£å†³
	am.checkResolvedAlerts(ctx, health)
}

// evaluateRules è¯„ä¼°å‘Šè­¦è§„åˆ™
func (am *AlertManager) evaluateRules(ctx context.Context, serviceName string, check HealthCheck) {
	for _, rule := range am.rules {
		if rule.Component != "" && rule.Component != check.Name {
			continue
		}

		// æ£€æŸ¥å†·å´æ—¶é—´
		if time.Since(rule.lastTriggered) < rule.Cooldown {
			continue
		}

		// è¯„ä¼°æ¡ä»¶
		if am.evaluateCondition(rule.Condition, serviceName, check) {
			rule.lastTriggered = time.Now()
			am.triggerAlert(ctx, rule, serviceName, check)
		}
	}
}

// evaluateCondition è¯„ä¼°å‘Šè­¦æ¡ä»¶
func (am *AlertManager) evaluateCondition(condition AlertCondition, serviceName string, check HealthCheck) bool {
	// æ£€æŸ¥çŠ¶æ€æ¡ä»¶
	if condition.StatusEquals != nil && check.Status == *condition.StatusEquals {
		return true
	}

	// æ£€æŸ¥å“åº”æ—¶é—´æ¡ä»¶
	if condition.ResponseTimeGT != nil && check.Duration > *condition.ResponseTimeGT {
		return true
	}

	// æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°
	if condition.ConsecutiveFails != nil {
		componentKey := fmt.Sprintf("%s:%s", serviceName, check.Name)
		if am.consecutiveFails[componentKey] >= *condition.ConsecutiveFails {
			return true
		}
	}

	return false
}

// triggerAlert è§¦å‘å‘Šè­¦
func (am *AlertManager) triggerAlert(ctx context.Context, rule AlertRule, serviceName string, check HealthCheck) {
	alertID := fmt.Sprintf("%s-%s-%d", serviceName, check.Name, time.Now().Unix())

	alert := Alert{
		ID:        alertID,
		Service:   serviceName,
		Component: check.Name,
		Level:     rule.Level,
		Status:    check.Status,
		Message:   fmt.Sprintf(rule.Message, check.Name, check.Status, check.Message),
		Details:   check.Details,
		Timestamp: time.Now(),
		Resolved:  false,
	}

	// ä¿å­˜æ´»è·ƒå‘Šè­¦
	am.activeAlerts[alertID] = &alert

	// æ·»åŠ åˆ°å†å²è®°å½•
	am.addToHistory(alert)

	// å‘é€å‘Šè­¦åˆ°æ‰€æœ‰æ¸ é“
	for _, channel := range am.channels {
		ch := channel
		go func(ch AlertChannel) {
			if err := ch.Send(ctx, alert); err != nil {
				am.logger.WithFields(pkglogger.Fields{
					"channel": ch.Name(),
					"alertId": alert.ID,
					"error":   err,
				}).Error("failed to dispatch alert")
			}
		}(ch)
	}

	am.logger.WithFields(pkglogger.Fields{
		"alertId":   alert.ID,
		"level":     alert.Level,
		"service":   alert.Service,
		"component": alert.Component,
	}).Info("alert triggered")
}

// checkResolvedAlerts æ£€æŸ¥å·²è§£å†³çš„å‘Šè­¦
func (am *AlertManager) checkResolvedAlerts(ctx context.Context, health ServiceHealth) {
	for alertID, alert := range am.activeAlerts {
		if alert.Resolved {
			continue
		}

		// æŸ¥æ‰¾å¯¹åº”çš„å¥åº·æ£€æŸ¥
		for _, check := range health.Checks {
			if check.Name == alert.Component && check.Status == StatusHealthy {
				// æ ‡è®°å‘Šè­¦ä¸ºå·²è§£å†³
				alert.Resolved = true
				now := time.Now()
				alert.ResolvedAt = &now

				// å‘é€è§£å†³é€šçŸ¥
				resolvedAlert := *alert
				resolvedAlert.Message = fmt.Sprintf("âœ… å‘Šè­¦å·²è§£å†³: %s ç»„ä»¶ %s æ¢å¤æ­£å¸¸", alert.Service, alert.Component)
				resolvedAlert.Level = AlertLevelInfo

				for _, channel := range am.channels {
					ch := channel
					go func(ch AlertChannel) {
						if err := ch.Send(ctx, resolvedAlert); err != nil {
							am.logger.WithFields(pkglogger.Fields{
								"channel": ch.Name(),
								"alertId": alert.ID,
								"error":   err,
							}).Error("failed to dispatch resolved alert")
						}
					}(ch)
				}

				am.logger.WithFields(pkglogger.Fields{
					"alertId":   alert.ID,
					"service":   alert.Service,
					"component": alert.Component,
				}).Info("alert resolved")
				delete(am.activeAlerts, alertID)
				break
			}
		}
	}
}

// addToHistory æ·»åŠ åˆ°å†å²è®°å½•
func (am *AlertManager) addToHistory(alert Alert) {
	am.alertHistory = append(am.alertHistory, alert)

	// ä¿æŒå†å²è®°å½•å¤§å°é™åˆ¶
	if len(am.alertHistory) > am.maxHistorySize {
		am.alertHistory = am.alertHistory[1:]
	}
}

// GetActiveAlerts è·å–æ´»è·ƒå‘Šè­¦
func (am *AlertManager) GetActiveAlerts() []Alert {
	am.mu.RLock()
	defer am.mu.RUnlock()

	alerts := make([]Alert, 0, len(am.activeAlerts))
	for _, alert := range am.activeAlerts {
		alerts = append(alerts, *alert)
	}

	return alerts
}

// GetAlertHistory è·å–å‘Šè­¦å†å²
func (am *AlertManager) GetAlertHistory(limit int) []Alert {
	am.mu.RLock()
	defer am.mu.RUnlock()

	if limit <= 0 || limit > len(am.alertHistory) {
		limit = len(am.alertHistory)
	}

	start := len(am.alertHistory) - limit
	return am.alertHistory[start:]
}
